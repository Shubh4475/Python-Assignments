{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **THEORETICAL QUESTIONS:**"
      ],
      "metadata": {
        "id": "NCGokY6_tZ3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is Logistic Regression, and how does it differ from Linear Regression.**"
      ],
      "metadata": {
        "id": "COhvE1kRtvYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:**  \n",
        "### **Logistic Regression**\n",
        "Logistic Regression is a statistical technique used for **binary classification** problems—where the outcome is either 0 or 1, Yes or No, Spam or Not Spam, etc. Unlike Linear Regression, which predicts continuous values, Logistic Regression predicts the **probability** that a given input belongs to a particular category.\n",
        "\n",
        "Mathematically, it uses the **sigmoid function** to map predictions into a probability range (0 to 1):\n",
        "$$\\[\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "]$$\n",
        "where \\( z \\) is a linear combination of input features.\n",
        "\n",
        "### **Linear Regression vs. Logistic Regression**\n",
        "| Feature | Linear Regression | Logistic Regression |\n",
        "|---------|-----------------|---------------------|\n",
        "| **Output Type** | Continuous values (e.g., house prices) | Probabilities for classification (e.g., spam detection) |\n",
        "| **Function Used** | Straight-line equation: \\( Y = mX + b \\) | Sigmoid function for probability mapping |\n",
        "| **Goal** | Predict exact numeric values | Classify data into discrete categories |\n",
        "| **Use Cases** | Stock price prediction, weather forecasting | Fraud detection, sentiment analysis |\n",
        "\n",
        "### **Example**\n",
        "- **Linear Regression**: Predicting a house price based on square footage.\n",
        "- **Logistic Regression**: Predicting whether an email is spam or not.\n",
        "\n"
      ],
      "metadata": {
        "id": "0HEbLDzRt1ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. What is the mathematical equation of Logistic Regression?**"
      ],
      "metadata": {
        "id": "l2ssjCHmvz1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** The mathematical equation for **Logistic Regression** is based on the **sigmoid function**, which maps any real-valued number into a probability range (0 to 1). Here's how it works:\n",
        "\n",
        "### **Equation for Logistic Regression**\n",
        "$$[\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "]$$\n",
        "where:\n",
        "- \\( sigma(z) \\) is the predicted probability (between 0 and 1),\n",
        "- \\( z \\) is the linear combination of input features,\n",
        "- \\( e \\) is Euler's number (≈ 2.718).\n",
        "\n",
        "Now, if we express \\( z \\) as a linear combination of features:\n",
        "\n",
        "$$[\n",
        "z = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n\n",
        "]$$\n",
        "\n",
        "Then the final **logistic regression model** becomes:\n",
        "\n",
        "$$[\n",
        "p = \\frac{1}{1 + e^{-(w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n)}}\n",
        "]$$\n",
        "\n",
        "where:\n",
        "- \\( w_0 \\) is the bias (intercept),\n",
        "- \\( w_1, w_2, \\dots, w_n \\) are the model's learned weights,\n",
        "- \\( x_1, x_2, \\dots, x_n \\) are the input features.\n",
        "\n",
        "This equation helps predict the **probability of belonging to class 1** (e.g., \"Spam\" in an email classifier). If \\( p \\) is greater than a threshold (usually 0.5), the model predicts **class 1**, otherwise, it predicts **class 0**.\n",
        "\n"
      ],
      "metadata": {
        "id": "a2c9ALSdv5ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.Why do we use the Sigmoid function in Logistic Regression?**"
      ],
      "metadata": {
        "id": "_6ZfhMGxxGA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** The **sigmoid function** plays a crucial role in **Logistic Regression**, primarily because it helps convert linear outputs into probabilities. Here’s why it's used:\n",
        "\n",
        "### **1. Converts Values into Probability Range (0 to 1)**\n",
        "- Logistic Regression needs to classify data into categories (e.g., spam or not spam).\n",
        "- A linear equation produces outputs that can range from negative to positive infinity.\n",
        "- The **sigmoid function** ensures that every output is transformed into a probability **between 0 and 1**, making it useful for classification.\n",
        "\n",
        "### **2. Decision Boundary for Classification**\n",
        "- The sigmoid function outputs values **close to 1 or 0** based on the input.\n",
        "- A common threshold (like **0.5**) is used to classify a sample into either **class 1 (positive)** or **class 0 (negative)**.\n",
        "  \n",
        "### **3. Continuous and Differentiable (Useful for Optimization)**\n",
        "- Since the sigmoid function is **smooth and differentiable**, it helps in gradient-based optimization methods like **Gradient Descent**.\n",
        "- The gradient of the sigmoid function allows the model to **adjust weights efficiently** and improve prediction accuracy.\n",
        "\n",
        "### **Mathematical Representation**\n",
        "$$[\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "]$$\n",
        "where:\n",
        "- \\( z \\) is a linear combination of inputs and weights.\n",
        "- \\( \\sigma(z) \\) gives the probability of belonging to class 1.\n",
        "\n",
        "### **Visualization**\n",
        "If you plot the sigmoid function, it creates an **S-shaped curve**, meaning:\n",
        "- **Inputs far greater than 0** approach **1** (high probability for class 1).\n",
        "- **Inputs far less than 0** approach **0** (high probability for class 0).\n",
        "- **Inputs around 0** hover near **0.5**, where classification is uncertain.\n",
        "\n"
      ],
      "metadata": {
        "id": "gIWmCc_JxM9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. What is the cost function of Logistic Regression?**"
      ],
      "metadata": {
        "id": "H3tPc6NHxtq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** The **cost function** in **Logistic Regression** is used to measure how well the model’s predictions match the actual labels. Unlike Linear Regression, which uses Mean Squared Error (MSE), Logistic Regression uses the **Log Loss (Cross-Entropy Loss)** as its cost function.\n",
        "\n",
        "### **Mathematical Formula**\n",
        "The **logistic regression cost function** is derived from the **likelihood function** for a Bernoulli distribution. It is given by:\n",
        "\n",
        "$$[\n",
        "J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(h_\\theta(x_i)) + (1 - y_i) \\log(1 - h_\\theta(x_i)) \\right]\n",
        "]$$\n",
        "\n",
        "where:\n",
        "- \\( J(θ) \\) is the cost function.\n",
        "- \\( m \\) is the number of training examples.\n",
        "- $( y_i$) is the actual class label (either 0 or 1).\n",
        "- $( h_\\theta(x_i) $\\) is the predicted probability from the **sigmoid function**.\n",
        "- $log(h_\\theta(x_i)) $ ensures penalties when predicting incorrect probabilities.\n",
        "\n",
        "### **Why Logarithmic Loss?**\n",
        "- **If \\( y = 1 \\) and $h_\\theta(x) $ is close to 1**, the loss is **small** (good prediction).\n",
        "- **If \\( y = 1 \\) but $h_\\theta(x)$ is close to 0**, the loss is **large** (bad prediction).\n",
        "- **Logarithmically penalizes confident wrong predictions**, making the model more cautious.\n",
        "\n",
        "### **Gradient Descent Optimization**\n",
        "To minimize the cost function, **Gradient Descent** iteratively adjusts the weights \\( \\theta \\) based on the partial derivatives of $ J(\\theta)$. This helps the model improve classification accuracy.\n"
      ],
      "metadata": {
        "id": "y4bLYZrJxyjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. What is Regularization in Logistic Regression? Why is it needed?**"
      ],
      "metadata": {
        "id": "zcW_vSrOzJNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Regularization in **Logistic Regression** is a technique used to **prevent overfitting** by penalizing excessively large coefficients in the model. When a model becomes too complex, it may perform well on training data but poorly on unseen data—this is where regularization helps.\n",
        "\n",
        "### **Why is Regularization Needed?**\n",
        "- **Overfitting Prevention:** When a model memorizes the training data instead of generalizing patterns, it leads to poor performance on new data.\n",
        "- **Feature Scaling Control:** Some features might dominate the model if they have large weights, leading to biased predictions.\n",
        "- **Stability in Predictions:** Regularization ensures smoother, more robust predictions by discouraging extreme coefficient values.\n",
        "\n",
        "### **Types of Regularization in Logistic Regression**\n",
        "#### **1. L1 Regularization (Lasso Regression)**\n",
        "- Adds a **penalty** equal to the sum of the absolute values of coefficients.\n",
        "- Encourages **sparse models** (some weights become exactly 0).\n",
        "- Formula:\n",
        "  $[\n",
        "  J(\\theta) = -\\frac{1}{m} \\sum \\left[ y \\log h_\\theta(x) + (1 - y) \\log (1 - h_\\theta(x) ) \\right] + \\lambda \\sum |w_i|\n",
        "  ]$\n",
        "- **Used for** feature selection because it eliminates irrelevant features.\n",
        "\n",
        "#### **2. L2 Regularization (Ridge Regression)**\n",
        "- Adds a **penalty** equal to the sum of squared coefficients.\n",
        "- Shrinks weights gradually instead of eliminating them.\n",
        "- Formula:\n",
        "  $[\n",
        "  J(\\theta) = -\\frac{1}{m} \\sum \\left[ y \\log h_\\theta(x) + (1 - y) \\log (1 - h_\\theta(x) ) \\right] + \\lambda \\sum w_i^2\n",
        "  ]$\n",
        "- **Used for** preventing overfitting while keeping all features.\n",
        "\n",
        "### **Which Regularization to Use?**\n",
        "- If you want **feature selection**, L1 Regularization is better.\n",
        "- If you want **to avoid overfitting without eliminating features**, L2 Regularization is ideal.\n",
        "- Some models use **Elastic Net**, a combination of L1 and L2.\n"
      ],
      "metadata": {
        "id": "MmldSomQzVx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. Explain the difference between Lasso, Ridge, and Elastic Net regression.**"
      ],
      "metadata": {
        "id": "RBuIIPOGzmCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** These three regression techniques—**Lasso, Ridge, and Elastic Net**—are used to **prevent overfitting** and improve model generalization by applying regularization. Here’s how they differ:\n",
        "\n",
        "### **1. Lasso Regression (L1 Regularization)**\n",
        "- **Penalty:** Adds the **absolute values** of the coefficients.\n",
        "- **Effect:** Shrinks some coefficients to exactly **zero**, effectively removing irrelevant features.\n",
        "- **Best For:** **Feature selection**—helps identify the most important features.\n",
        "- **Formula:**\n",
        "  $[\n",
        "  J(\\theta) = \\text{Loss} + \\lambda \\sum |w_i|\n",
        "  ]$\n",
        "- **Key Point:** If you want **sparse models** with fewer features, use **Lasso**!\n",
        "\n",
        "### **2. Ridge Regression (L2 Regularization)**\n",
        "- **Penalty:** Adds the **squared values** of the coefficients.\n",
        "- **Effect:** Shrinks all coefficients **but does not set any to zero**.\n",
        "- **Best For:** When **all features are important**, but you want to reduce extreme coefficients.\n",
        "- **Formula:**\n",
        "  $[\n",
        "  J(\\theta) = \\text{Loss} + \\lambda \\sum w_i^2\n",
        "  ]$\n",
        "- **Key Point:** If you want to **keep all features but prevent overfitting**, use **Ridge**!\n",
        "\n",
        "### **3. Elastic Net (Combination of L1 & L2)**\n",
        "- **Penalty:** Uses a mix of **both L1 and L2 regularization**.\n",
        "- **Effect:** **Selects important features (Lasso) while shrinking coefficients (Ridge)**.\n",
        "- **Best For:** When **features are correlated** (high multicollinearity).\n",
        "- **Formula:**\n",
        "  $[\n",
        "  J(\\theta) = \\text{Loss} + \\lambda_1 \\sum |w_i| + \\lambda_2 \\sum w_i^2\n",
        "  ]$\n",
        "- **Key Point:** If you need **feature selection AND coefficient shrinkage**, use **Elastic Net**!\n",
        "\n",
        "### **Comparison Table**\n",
        "| Method | Regularization Type | Effect on Coefficients | Feature Selection? |\n",
        "|--------|----------------------|----------------------|--------------------|\n",
        "| **Lasso** | L1 (Absolute values) | Some coefficients set to **zero** | ✅ Yes |\n",
        "| **Ridge** | L2 (Squared values) | Shrinks coefficients but **keeps all** | ❌ No |\n",
        "| **Elastic Net** | L1 + L2 | Shrinks and selects features | ✅ Yes (but not sparse like Lasso) |\n",
        "\n",
        "### **Which One Should You Use?**\n",
        "- **Lasso** → When you want feature selection.\n",
        "- **Ridge** → When all features are relevant but need regularization.\n",
        "- **Elastic Net** → When features are correlated or Lasso is too aggressive.\n"
      ],
      "metadata": {
        "id": "4UD8DYOszrnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.  When should we use Elastic Net instead of Lasso or Ridge?**"
      ],
      "metadata": {
        "id": "EO7cPBu90AEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Elastic Net is a great choice when **Lasso and Ridge individually have limitations** in handling certain data characteristics. Here’s when to use it:\n",
        "\n",
        "### **1. When Features Are Highly Correlated**\n",
        "- **Lasso (L1 regularization)** tends to randomly drop one correlated feature while keeping another, which can lead to unstable feature selection.\n",
        "- **Elastic Net combines L1 and L2** to **keep correlated features**, instead of discarding one arbitrarily.\n",
        "\n",
        "### **2. When Lasso is Too Aggressive in Shrinking Coefficients**\n",
        "- Lasso can push coefficients **exactly to zero**, which might **oversimplify** the model and remove too many important features.\n",
        "- Elastic Net **balances feature selection** while still keeping some variables slightly weighted.\n",
        "\n",
        "### **3. When Ridge Retains All Features Unnecessarily**\n",
        "- Ridge regularization only shrinks coefficients but **never eliminates features**, which might be unnecessary if some features are unimportant.\n",
        "- Elastic Net **ensures important features are kept** while reducing the influence of weak ones.\n",
        "\n",
        "### **Best Case for Elastic Net?**\n",
        "- When the dataset has **strong multicollinearity** (features are interrelated).\n",
        "- When you want **some level of feature selection**, but don’t want Lasso’s extreme behavior.\n",
        "- When Ridge is keeping too many irrelevant features.\n"
      ],
      "metadata": {
        "id": "td5ChAVb0Fwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8.  What is the impact of the regularization parameter (λ) in Logistic Regression?**"
      ],
      "metadata": {
        "id": "FTBE2kjY0be8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** The regularization parameter **λ (lambda)** in Logistic Regression controls the **strength** of regularization. Its impact varies based on its value:\n",
        "\n",
        "### **1. Low λ (Minimal Regularization)**\n",
        "- When **λ is close to 0**, regularization is weak.\n",
        "- The model behaves like **standard Logistic Regression**, relying solely on fitting the data.\n",
        "- It may **overfit** by learning high-magnitude weights, capturing noise rather than general trends.\n",
        "\n",
        "### **2. High λ (Strong Regularization)**\n",
        "- Large **λ heavily penalizes** large coefficients.\n",
        "- Forces the model to learn **simpler, more generalized** patterns by shrinking weights.\n",
        "- Prevents overfitting but may lead to **underfitting**, where the model fails to capture relationships in the data.\n",
        "\n",
        "### **3. Impact on Lasso (L1) and Ridge (L2) Regularization**\n",
        "- **L1 (Lasso)**: With high **λ**, some coefficients shrink **to zero**, effectively removing features.\n",
        "- **L2 (Ridge)**: With high **λ**, coefficients shrink **but never reach zero**, keeping all features.\n",
        "\n",
        "### **Choosing the Right λ**\n",
        "- **Small λ** → If your model is underfitting, reduce regularization.\n",
        "- **Large λ** → If your model is overfitting, increase regularization.\n",
        "- **Cross-validation** helps find the optimal λ value for best performance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u-y04zjt0fwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9. What are the key assumptions of Logistic Regression?**"
      ],
      "metadata": {
        "id": "v9Nn3xXP0q3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Logistic Regression, like any machine learning algorithm, operates under certain **assumptions** to ensure its effectiveness. While it is more flexible than Linear Regression, it still has key assumptions:\n",
        "\n",
        "### **1. Independent Variables are Linearly Related to Log-Odds**\n",
        "- Logistic Regression assumes a **linear relationship** between the independent variables (**features**) and the **log of odds** of the dependent variable.\n",
        "- It doesn’t assume a direct linear relationship between features and the outcome but between features and the **logit function**.\n",
        "\n",
        "### **2. No Multicollinearity Among Independent Variables**\n",
        "- Highly correlated features can cause instability in coefficient estimates.\n",
        "- Regularization techniques like **Ridge (L2) or Elastic Net** can help mitigate this issue.\n",
        "\n",
        "### **3. Independence of Observations**\n",
        "- Each observation should be **independent**, meaning there should be no autocorrelation (e.g., repeated measures from the same individual).\n",
        "- If observations are dependent, techniques like **Generalized Estimating Equations (GEE)** or mixed models should be used.\n",
        "\n",
        "### **4. The Dependent Variable is Binary or Multiclass (Categorical)**\n",
        "- **Binary Logistic Regression** assumes the target variable is **strictly 0 or 1**.\n",
        "- For **multiclass classification**, **Softmax regression** (or multinomial logistic regression) is used.\n",
        "\n",
        "### **5. Large Sample Size**\n",
        "- Logistic Regression performs best with **a sufficient number of observations** to estimate probabilities accurately.\n",
        "- Small datasets may lead to unstable parameter estimates.\n",
        "\n",
        "### **6. No Extreme Outliers**\n",
        "- Outliers can distort probability estimates and decision boundaries.\n",
        "- Standardization techniques or robust models help minimize their effect.\n",
        "\n",
        "### **7. Appropriately Distributed Errors (Homoscedasticity is Not Required)**\n",
        "- Unlike Linear Regression, Logistic Regression does **not** assume **constant variance** in errors (homoscedasticity).\n",
        "- Instead, it assumes that errors are **randomly distributed**.\n",
        "\n"
      ],
      "metadata": {
        "id": "gDfsxpVD05-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10. What are some alternatives to Logistic Regression for classification tasks?**"
      ],
      "metadata": {
        "id": "EV-Z97h50-aN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** There are several alternatives to **Logistic Regression** for classification tasks, each offering unique strengths depending on the dataset and problem complexity. Here are some commonly used alternatives:\n",
        "\n",
        "### **1. Decision Trees**\n",
        "- Based on splitting data using **if-else conditions**.\n",
        "- Can handle **non-linear relationships**.\n",
        "- Works well for **interpretability** but prone to **overfitting**.\n",
        "\n",
        "### **2. Random Forest**\n",
        "- An ensemble of multiple **Decision Trees**.\n",
        "- **Reduces overfitting** and improves accuracy.\n",
        "- Works well for **both classification and regression**.\n",
        "\n",
        "### **3. Support Vector Machines (SVM)**\n",
        "- Finds the **optimal hyperplane** that separates classes.\n",
        "- Effective for **high-dimensional** data.\n",
        "- Supports **non-linear classification** using kernels.\n",
        "\n",
        "### **4. K-Nearest Neighbors (KNN)**\n",
        "- Classifies based on the **majority vote** of nearest neighbors.\n",
        "- Simple, intuitive but **computationally expensive** with large datasets.\n",
        "\n",
        "### **5. Naïve Bayes**\n",
        "- Based on **Bayesian probability**.\n",
        "- Assumes **independence** between features.\n",
        "- Works well for **text classification (spam detection, sentiment analysis).**\n",
        "\n",
        "### **6. Gradient Boosting Models (GBM)**\n",
        "- Uses **boosted decision trees** for better accuracy.\n",
        "- Examples: **XGBoost, LightGBM, CatBoost**.\n",
        "- Strong performance in **structured data tasks**.\n",
        "\n",
        "### **7. Artificial Neural Networks (Deep Learning)**\n",
        "- Uses **multiple layers** to learn complex features.\n",
        "- Requires **large datasets** for effective learning.\n",
        "- Used in **image recognition, NLP**, and complex data patterns.\n",
        "\n",
        "### **Choosing the Right Alternative**\n",
        "- **If interpretability is important → Use Decision Trees or Naïve Bayes.**\n",
        "- **For large datasets with complex relationships → Try Gradient Boosting or Neural Networks.**\n",
        "- **If you need a simple but effective model → Use Random Forest or SVM.**\n",
        "\n"
      ],
      "metadata": {
        "id": "5sJgyTl41DQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11. What are Classification Evaluation Metrics?**"
      ],
      "metadata": {
        "id": "NSi_yAJt1PVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Classification evaluation metrics help assess the performance of classification models, ensuring they make accurate predictions. Here are the key metrics used:\n",
        "\n",
        "### **1. Accuracy**\n",
        "- Measures the percentage of correctly predicted instances.\n",
        "- Formula:\n",
        "  $[\n",
        "  Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "  ]$\n",
        "- **Limitation**: Can be misleading if the dataset is imbalanced.\n",
        "\n",
        "### **2. Precision**\n",
        "- Measures how many of the predicted **positive** instances are actually **positive**.\n",
        "- Formula:\n",
        "  $[\n",
        "  Precision = \\frac{TP}{TP + FP}\n",
        "  ]$\n",
        "- **Useful when false positives are costly**, like in medical diagnosis or fraud detection.\n",
        "\n",
        "### **3. Recall (Sensitivity)**\n",
        "- Measures how well the model **identifies actual positives**.\n",
        "- Formula:\n",
        "  $[\n",
        "  Recall = \\frac{TP}{TP + FN}\n",
        "  ]$\n",
        "- **Critical for imbalanced datasets**, where missing positive cases is more serious.\n",
        "\n",
        "### **4. F1 Score**\n",
        "- The harmonic mean of **Precision** and **Recall**.\n",
        "- Formula:\n",
        "  $[\n",
        "  F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n",
        "  ]$\n",
        "- **Best for balancing false positives and false negatives**.\n",
        "\n",
        "### **5. ROC Curve & AUC Score**\n",
        "- **ROC Curve**: Plots **True Positive Rate (Recall)** vs. **False Positive Rate**.\n",
        "- **AUC (Area Under Curve)**: Measures the ability to distinguish between classes.\n",
        "- **Higher AUC = Better classification performance**.\n",
        "\n",
        "### **6. Confusion Matrix**\n",
        "- Shows the breakdown of **True Positives (TP)**, **True Negatives (TN)**, **False Positives (FP)**, and **False Negatives (FN)**.\n",
        "- Helps analyze **where the model makes errors**.\n"
      ],
      "metadata": {
        "id": "gzwPEMIB1SJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12.  How does class imbalance affect Logistic Regression?**"
      ],
      "metadata": {
        "id": "dwiQdbIi1my5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Class imbalance can **significantly affect Logistic Regression**, leading to biased predictions. Here’s how:\n",
        "\n",
        "### **1. Bias Toward the Majority Class**\n",
        "- Logistic Regression **learns to minimize the cost function**, and when the dataset is imbalanced (e.g., 95% of samples belong to one class), the model **favors the majority class**.\n",
        "- It might classify **almost everything as the dominant class**, resulting in **high accuracy but poor recall for the minority class**.\n",
        "\n",
        "### **2. Misleading Accuracy Metric**\n",
        "- If 95% of samples are \"Class 0\" and only 5% are \"Class 1,\" a model predicting **everything as \"Class 0\"** would have **95% accuracy** but fail completely at detecting \"Class 1.\"\n",
        "- **Accuracy alone isn’t a good metric** in imbalanced datasets; metrics like **Precision, Recall, and F1 Score** are more reliable.\n",
        "\n",
        "### **3. Poor Decision Boundary Learning**\n",
        "- With imbalance, the model struggles to find an optimal **decision boundary**, often making **incorrect classifications** for the minority class.\n",
        "\n",
        "### **4. Lower Model Confidence for Minority Class Predictions**\n",
        "- Since Logistic Regression **learns from data distribution**, an underrepresented class gets fewer samples, making the model uncertain when predicting it.\n",
        "\n",
        "### **How to Handle Class Imbalance in Logistic Regression**\n",
        "✔ **Resampling Methods**:\n",
        "  - **Oversampling**: Increase minority class samples (e.g., **SMOTE** technique).\n",
        "  - **Undersampling**: Reduce majority class samples.\n",
        "\n",
        "✔ **Use Alternative Evaluation Metrics**:\n",
        "  - **Precision, Recall, F1 Score, and AUC-ROC**.\n",
        "\n",
        "✔ **Adjust Class Weights**:\n",
        "  - Assign **higher penalties** to the minority class using `class_weight='balanced'` in **Scikit-learn**.\n",
        "\n",
        "✔ **Use More Advanced Models**:\n",
        "  - Try **Tree-based models (Random Forest, XGBoost)** or ensemble techniques.\n",
        "\n"
      ],
      "metadata": {
        "id": "Zprws6BM1rdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13. What is Hyperparameter Tuning in Logistic Regression?**"
      ],
      "metadata": {
        "id": "1MxVkouD10aw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Hyperparameter tuning in **Logistic Regression** refers to the process of **optimizing model parameters** that are **not learned** during training but instead set **before** the learning process begins. These hyperparameters directly influence model performance.\n",
        "\n",
        "### **Key Hyperparameters in Logistic Regression**\n",
        "1. **Regularization Strength (C)**\n",
        "   - Controls the **inverse** of the regularization parameter \\( \\lambda \\).\n",
        "   - **Higher C** → Less regularization (risk of overfitting).\n",
        "   - **Lower C** → Stronger regularization (helps prevent overfitting).\n",
        "   - Example:\n",
        "     ```python\n",
        "     from sklearn.linear_model import LogisticRegression\n",
        "     model = LogisticRegression(C=0.1)  # Strong regularization\n",
        "     ```\n",
        "\n",
        "2. **Penalty Type (Regularization)**\n",
        "   - **L1 (Lasso)** → Feature selection (some coefficients become zero).\n",
        "   - **L2 (Ridge)** → Shrinks all coefficients but keeps all features.\n",
        "   - **Elastic Net** → Mix of L1 and L2 regularization.\n",
        "   - Example:\n",
        "     ```python\n",
        "     model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "     ```\n",
        "\n",
        "3. **Solver (Optimization Algorithm)**\n",
        "   - Defines how the model optimizes weights.\n",
        "   - Options:\n",
        "     - `'lbfgs'` → Default solver, works well for most cases.\n",
        "     - `'liblinear'` → Supports L1 regularization.\n",
        "     - `'saga'` → Good for large datasets and Elastic Net.\n",
        "   - Example:\n",
        "     ```python\n",
        "     model = LogisticRegression(solver='saga')\n",
        "     ```\n",
        "\n",
        "### **How to Tune Hyperparameters?**\n",
        "✔ **Grid Search** (`GridSearchCV`)\n",
        "   - Tries multiple hyperparameter values and finds the best combination.\n",
        "   ```python\n",
        "   from sklearn.model_selection import GridSearchCV\n",
        "   param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "   grid = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5)\n",
        "   grid.fit(X_train, y_train)\n",
        "   print(\"Best Parameters:\", grid.best_params_)\n",
        "   ```\n",
        "\n",
        "✔ **Random Search** (`RandomizedSearchCV`)\n",
        "   - Randomly samples hyperparameters instead of an exhaustive search.\n",
        "   ```python\n",
        "   from sklearn.model_selection import RandomizedSearchCV\n",
        "   random_search = RandomizedSearchCV(LogisticRegression(solver='liblinear'), param_grid, n_iter=10, cv=5)\n",
        "   ```\n",
        "\n",
        "✔ **Bayesian Optimization**\n",
        "   - More efficient tuning using probabilistic models.\n",
        "\n",
        "### **Why Hyperparameter Tuning is Important?**\n",
        "- **Prevents overfitting** by selecting the right regularization.\n",
        "- **Improves accuracy** by optimizing weight learning.\n",
        "- **Boosts model efficiency** by choosing the best solver.\n",
        "\n"
      ],
      "metadata": {
        "id": "y3mAIBFM144b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14. What are different solvers in Logistic Regression? Which one should be used?**"
      ],
      "metadata": {
        "id": "6HbKnHFn2H3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Logistic Regression in **Scikit-learn** offers multiple solvers, each with different optimization techniques for learning model parameters. The choice of solver depends on the dataset size, regularization type, and computational efficiency.\n",
        "\n",
        "### **Different Solvers in Logistic Regression**\n",
        "#### **1. liblinear**\n",
        "- Uses **Coordinate Descent** optimization.\n",
        "- Supports **L1 (Lasso) and L2 (Ridge) regularization**.\n",
        "- Works best for **small datasets**.\n",
        "- Example:\n",
        "  ```python\n",
        "  model = LogisticRegression(solver='liblinear', penalty='l1')\n",
        "  ```\n",
        "\n",
        "#### **2. lbfgs**\n",
        "- Uses **Limited-memory Broyden-Fletcher-Goldfarb-Shanno (LBFGS)**.\n",
        "- Default solver in Scikit-learn.\n",
        "- Supports **L2 regularization** but **not L1**.\n",
        "- Suitable for **medium-sized datasets**.\n",
        "- Example:\n",
        "  ```python\n",
        "  model = LogisticRegression(solver='lbfgs', penalty='l2')\n",
        "  ```\n",
        "\n",
        "#### **3. saga**\n",
        "- Uses **Stochastic Average Gradient Descent**.\n",
        "- Supports **L1, L2, and Elastic Net regularization**.\n",
        "- Ideal for **large datasets** and sparse data.\n",
        "- Example:\n",
        "  ```python\n",
        "  model = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.5)\n",
        "  ```\n",
        "\n",
        "#### **4. newton-cg**\n",
        "- Uses **Newton’s Conjugate Gradient Method**.\n",
        "- Suitable for **L2 regularization**.\n",
        "- Performs well with **high-dimensional data**.\n",
        "- Example:\n",
        "  ```python\n",
        "  model = LogisticRegression(solver='newton-cg')\n",
        "  ```\n",
        "\n",
        "#### **5. sag**\n",
        "- **Stochastic Gradient Descent Approximation**.\n",
        "- Works best for **large datasets**.\n",
        "- Supports only **L2 regularization**.\n",
        "- Example:\n",
        "  ```python\n",
        "  model = LogisticRegression(solver='sag', penalty='l2')\n",
        "  ```\n",
        "\n",
        "### **Which Solver Should You Use?**\n",
        "| Solver | Best For | Regularization Support | Dataset Size |\n",
        "|--------|---------|----------------------|--------------|\n",
        "| **liblinear** | Small datasets | L1, L2 | 🔹 Small |\n",
        "| **lbfgs** | Default choice | L2 | 🔸 Medium |\n",
        "| **saga** | Large datasets, sparse features | L1, L2, Elastic Net | 🔶 Large |\n",
        "| **newton-cg** | High-dimensional data | L2 | 🔸 Medium to Large |\n",
        "| **sag** | Large datasets | L2 | 🔶 Large |\n",
        "\n",
        "### **Choosing the Best Solver**\n",
        "✔ If you have a **small dataset**, use **liblinear**.  \n",
        "✔ If you need **L1 regularization**, **saga** or **liblinear** are best.  \n",
        "✔ If you need **Elastic Net regularization**, use **saga**.  \n",
        "✔ If your dataset is **large**, use **saga** or **sag** for faster computation.  \n",
        "\n"
      ],
      "metadata": {
        "id": "Ftol-ycR2MpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15.  How is Logistic Regression extended for multiclass classification?**"
      ],
      "metadata": {
        "id": "pNT8LYKo2bwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Logistic Regression is naturally suited for **binary classification**, but when handling **multiclass classification**, it must be extended using specific approaches. The two main techniques are:\n",
        "\n",
        "### **1. One-vs-Rest (OvR) / One-vs-All (OvA) Approach**\n",
        "- **How it Works**:\n",
        "  - The model creates **multiple binary classifiers**, one for each class.\n",
        "  - For a dataset with **3 classes (A, B, C)**:\n",
        "    - Model 1: A vs. (B & C)\n",
        "    - Model 2: B vs. (A & C)\n",
        "    - Model 3: C vs. (A & B)\n",
        "  - The class with the **highest probability** is selected.\n",
        "  \n",
        "- **Advantages**:\n",
        "  - Simple and interpretable.\n",
        "  - Works well for most problems.\n",
        "\n",
        "- **Disadvantages**:\n",
        "  - Multiple models must be trained, increasing computation.\n",
        "\n",
        "- **Python Example**:\n",
        "  ```python\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "  model.fit(X_train, y_train)\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Softmax (Multinomial Logistic Regression)**\n",
        "- **How it Works**:\n",
        "  - Uses a single model with the **Softmax function** to predict probabilities for all classes at once.\n",
        "  - The Softmax formula ensures that probability values sum to **1**, allowing the model to pick the most likely class:\n",
        "  \n",
        "    \\[\n",
        "    P(y_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n",
        "    \\]\n",
        "\n",
        "- **Advantages**:\n",
        "  - More efficient than OvR since only **one model** is trained.\n",
        "  - Works better when classes have **strong interdependencies**.\n",
        "\n",
        "- **Disadvantages**:\n",
        "  - Slightly more complex than OvR.\n",
        "\n",
        "- **Python Example**:\n",
        "  ```python\n",
        "  model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "  model.fit(X_train, y_train)\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **Which Approach Should We Use?**\n",
        "✔ Use **OvR** when you have **many classes** and want a simple, interpretable approach.  \n",
        "✔ Use **Softmax (Multinomial)** when classes are **strongly related** or when you need **probability-based decisions**.\n",
        "\n"
      ],
      "metadata": {
        "id": "y017Y0Jn2qmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16. What are the advantages and disadvantages of Logistic Regression?**"
      ],
      "metadata": {
        "id": "dbx1IhlA2yoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Logistic Regression is a widely used classification algorithm with several strengths and limitations. Here’s a breakdown:\n",
        "\n",
        "### **Advantages of Logistic Regression**\n",
        "✔ **Simple & Interpretable**  \n",
        "   - Easy to understand and implement.  \n",
        "   - Provides clear insight into feature importance via coefficients.\n",
        "\n",
        "✔ **Works Well for Linearly Separable Data**  \n",
        "   - Effective when there’s a **linear relationship** between features and the log odds of the target variable.\n",
        "\n",
        "✔ **Probability-Based Predictions**  \n",
        "   - Outputs probabilities, making it useful for applications requiring confidence estimation.\n",
        "\n",
        "✔ **Efficient for Large Datasets**  \n",
        "   - Computationally efficient compared to complex models like Decision Trees or Neural Networks.\n",
        "\n",
        "✔ **Regularization Support (L1 & L2)**  \n",
        "   - Helps prevent **overfitting**, ensuring better generalization.\n",
        "\n",
        "✔ **Handles Binary & Multiclass Classification**  \n",
        "   - Supports **One-vs-Rest (OvR) and Softmax** extensions for multiclass problems.\n",
        "\n",
        "---\n",
        "\n",
        "### **Disadvantages of Logistic Regression**\n",
        "❌ **Struggles with Non-Linear Relationships**  \n",
        "   - Doesn’t perform well if data is **highly non-linear** (Decision Trees or Neural Networks may work better).\n",
        "\n",
        "❌ **Requires Feature Engineering**  \n",
        "   - Works best when features are **properly scaled** (Standardization or Normalization needed).  \n",
        "   - **Multicollinearity can be problematic**, requiring techniques like PCA or regularization.\n",
        "\n",
        "❌ **Sensitive to Class Imbalance**  \n",
        "   - May **favor the majority class**, leading to poor predictions for rare events (e.g., fraud detection).  \n",
        "   - **Solutions**: Use **class weighting or resampling**.\n",
        "\n",
        "❌ **Assumes Independence of Features**  \n",
        "   - If features are highly correlated, it may **produce unstable coefficients**.  \n",
        "   - **Solutions**: Use **Ridge Regularization (L2) or Elastic Net**.\n",
        "\n",
        "---\n",
        "\n",
        "### **When to Use Logistic Regression?**\n",
        "✔ When the relationship between **features and the log-odds of the target is linear**.  \n",
        "✔ When **interpretability is important** and you need probability-based decisions.  \n",
        "✔ When you have a **simple dataset with structured features**.  \n",
        "✔ When computational efficiency is a priority.\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "owC4gdWM3R4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17. What are some use cases of Logistic Regression?**"
      ],
      "metadata": {
        "id": "eMuvrUjF3ea4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Logistic Regression is widely used in various fields where binary or multiclass classification is required. Here are some key use cases:\n",
        "\n",
        "### **1. Medical Diagnosis**\n",
        "✔ Predicting diseases based on symptoms (e.g., **diabetes detection**, heart disease prediction).  \n",
        "✔ Used in **tumor classification** (benign vs. malignant).\n",
        "\n",
        "### **2. Fraud Detection**\n",
        "✔ Detecting **credit card fraud** based on transaction patterns.  \n",
        "✔ Identifying fraudulent insurance claims.\n",
        "\n",
        "### **3. Spam Email Filtering**\n",
        "✔ Classifies emails as **spam or not spam** using text-based features.  \n",
        "✔ Helps improve cybersecurity in email systems.\n",
        "\n",
        "### **4. Customer Churn Prediction**\n",
        "✔ Determines whether customers are likely to **leave a service**.  \n",
        "✔ Helps businesses retain customers through targeted strategies.\n",
        "\n",
        "### **5. Sentiment Analysis**\n",
        "✔ Used to **classify text** as positive, negative, or neutral (e.g., product reviews, social media analysis).  \n",
        "✔ Helps brands understand customer feedback.\n",
        "\n",
        "### **6. Credit Scoring & Loan Default Prediction**\n",
        "✔ Predicts whether a person will **repay a loan or default** based on financial history.  \n",
        "✔ Commonly used in banking and finance.\n",
        "\n",
        "### **7. Employee Attrition Prediction**\n",
        "✔ Determines whether employees are **likely to leave** based on work environment, salary, and job satisfaction.\n",
        "\n",
        "### **8. Image Recognition**\n",
        "✔ Applied in **character recognition** (e.g., handwritten digit classification like MNIST dataset).  \n",
        "✔ Used in facial recognition systems.\n",
        "\n",
        "### **9. Marketing & Advertising**\n",
        "✔ Predicts whether customers will **click on ads or buy a product** based on historical behavior.  \n",
        "✔ Helps optimize ad targeting.\n",
        "\n",
        "### **10. Political Polling & Elections**\n",
        "✔ Forecasts voting preferences based on demographic data and past voting trends.\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "m6T-fDLT3jPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18.  What is the difference between Softmax Regression and Logistic Regression?**"
      ],
      "metadata": {
        "id": "pFf4mZYH3t1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Softmax Regression and Logistic Regression are closely related, but they serve different purposes in classification tasks. Here’s how they differ:\n",
        "\n",
        "### **1. Purpose and Application**\n",
        "- **Logistic Regression**: Used for **binary classification** (e.g., spam vs. not spam, disease present vs. absent).\n",
        "- **Softmax Regression**: Used for **multiclass classification** (e.g., classifying images into categories like cat, dog, and bird).\n",
        "\n",
        "### **2. Mathematical Function**\n",
        "- **Logistic Regression**: Uses the **sigmoid function** to convert predictions into probabilities between **0 and 1**:\n",
        "  $[\n",
        "  \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "  ]$\n",
        "- **Softmax Regression**: Uses the **softmax function** to convert predictions into probabilities across **multiple classes**, ensuring they sum to 1:\n",
        "  $[\n",
        "  P(y_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n",
        "  ]$\n",
        "  - Each class gets a probability score, and the highest one determines the final classification.\n",
        "\n",
        "### **3. Output Interpretation**\n",
        "- **Logistic Regression**: Outputs a single probability score; if **\\( p > 0.5 \\)**, it predicts class **1**, otherwise class **0**.\n",
        "- **Softmax Regression**: Outputs probabilities for **all classes** simultaneously; the class with the **highest probability** is chosen.\n",
        "\n",
        "### **4. Decision Boundary**\n",
        "- **Logistic Regression**: Finds a **linear boundary** between two classes.\n",
        "- **Softmax Regression**: Finds **multiple boundaries** to separate multiple classes.\n",
        "\n",
        "### **5. Implementation in Python**\n",
        "✔ Logistic Regression for binary classification:\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "✔ Softmax Regression for multiclass classification:\n",
        "```python\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### **Which One Should You Use?**\n",
        "- If the task is **binary classification** → Use **Logistic Regression**.\n",
        "- If the task involves **three or more classes** → Use **Softmax Regression**.\n",
        "\n"
      ],
      "metadata": {
        "id": "mdZT6wMW398f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**"
      ],
      "metadata": {
        "id": "JWt2X_BL4Pgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Choosing between **One-vs-Rest (OvR)** and **Softmax (Multinomial Logistic Regression)** depends on the **dataset structure, number of classes, and computational efficiency**. Here’s how to decide:\n",
        "\n",
        "### **1. When to Use One-vs-Rest (OvR)**\n",
        "✔ **Few classes with independent characteristics**  \n",
        "   - OvR trains **multiple binary classifiers**, which works well when classes don’t overlap much.  \n",
        "\n",
        "✔ **Efficient for smaller datasets**  \n",
        "   - Computationally simpler for **low-dimensional data**.  \n",
        "\n",
        "✔ **Easy to implement & interpret**  \n",
        "   - Each classifier predicts a binary decision (e.g., \"Is it Class A or not?\").  \n",
        "\n",
        "✔ **Works well when class distribution is uneven**  \n",
        "   - Helps when some classes have significantly fewer examples than others.  \n",
        "\n",
        "#### **Python Example**\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **2. When to Use Softmax (Multinomial Logistic Regression)**\n",
        "✔ **When classes are closely related**  \n",
        "   - Softmax calculates probabilities for all classes at once, making it better for **interdependent categories** (e.g., classifying animals as cat, dog, or fox).  \n",
        "\n",
        "✔ **Better for larger datasets & high-dimensional features**  \n",
        "   - Works efficiently with **deep learning models** and structured data.  \n",
        "\n",
        "✔ **More accurate probability estimation**  \n",
        "   - Provides a probability **distribution across all classes**, ensuring better ranking.  \n",
        "\n",
        "✔ **Computationally efficient for many classes**  \n",
        "   - Instead of multiple classifiers, **one model predicts all classes at once**.  \n",
        "\n",
        "#### **Python Example**\n",
        "```python\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Which One Should You Choose?**\n",
        "| Criteria | **One-vs-Rest (OvR)** | **Softmax (Multinomial)** |\n",
        "|----------|----------------------|---------------------------|\n",
        "| **Number of Classes** | Few classes | Many classes |\n",
        "| **Class Independence** | Works well when classes are distinct | Works better when classes are interrelated |\n",
        "| **Computational Complexity** | Lower | Higher (but more efficient for large datasets) |\n",
        "| **Probability Interpretation** | Each binary classifier predicts class membership separately | Generates probabilities for all classes at once |\n",
        "| **Best Use Case** | Simple problems, imbalanced data | Complex classification tasks, deep learning |\n",
        "\n",
        "✔ **Use OvR** if your classes are independent and you prefer interpretability.  \n",
        "✔ **Use Softmax** if your classes are closely related and you need probability distribution across all labels.  \n",
        "\n"
      ],
      "metadata": {
        "id": "slVb7WWS4T9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20. How do we interpret coefficients in Logistic Regression?**"
      ],
      "metadata": {
        "id": "I3HXfU0x4eCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Interpreting **coefficients in Logistic Regression** helps us understand the relationship between **input features** and the probability of an outcome. Since Logistic Regression predicts probabilities rather than continuous values, the coefficients must be interpreted differently than in Linear Regression.\n",
        "\n",
        "### **How to Interpret Coefficients in Logistic Regression**\n",
        "Each coefficient (\\( w_i \\)) represents the **log-odds** of the outcome changing based on an increase in the corresponding feature \\( x_i \\).\n",
        "\n",
        "#### **1. Log-Odds Interpretation**\n",
        "- The Logistic Regression model uses the equation:\n",
        "  $[\n",
        "  \\log\\left(\\frac{p}{1-p}\\right) = w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n\n",
        "  ]$\n",
        "  - $( p )$ = probability of the positive class.\n",
        "  - $( w_i )$ = coefficient for feature \\( x_i \\).\n",
        "\n",
        "- If $( w_i > 0 )$, **the feature increases the probability of the positive class**.\n",
        "- If $( w_i < 0 )$, **the feature decreases the probability** of the positive class.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Odds Ratio Interpretation**\n",
        "Instead of interpreting raw coefficients, we often use the **odds ratio**, which is **exponentiated**:\n",
        "  $[\n",
        "  e^{w_i}\n",
        "  ]$\n",
        "- If $( e^{w_i} > 1 )$, increasing $( x_i )$ **increases** the odds of the positive class.\n",
        "- If $( e^{w_i} < 1 )$, increasing $( x_i )$ **decreases** the odds of the positive class.\n",
        "- If $( e^{w_i} \\approx 1 )$, $( x_i )$ has **little effect** on classification.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example in Python**\n",
        "To compute and interpret coefficients in **Scikit-learn**:\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Sample dataset\n",
        "X = np.array([[2, 1], [3, 0], [5, 1], [6, 0], [7, 1]])\n",
        "y = np.array([0, 0, 1, 1, 1])\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Extract coefficients\n",
        "coefficients = model.coef_[0]\n",
        "odds_ratios = np.exp(coefficients)\n",
        "\n",
        "# Display results\n",
        "df = pd.DataFrame({'Feature': ['X1', 'X2'], 'Coefficient': coefficients, 'Odds Ratio': odds_ratios})\n",
        "print(df)\n",
        "```\n",
        "\n",
        "This will show:\n",
        "✔ The **coefficients** that influence classification.  \n",
        "✔ Their **odds ratio interpretation** to better understand the impact.\n",
        "\n"
      ],
      "metadata": {
        "id": "X3t1VFCF4nIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PRACTICAL QUESTIONS:**"
      ],
      "metadata": {
        "id": "WpQHTDEg5LVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic**\n",
        "**Regression, and prints the model accuracy.**"
      ],
      "metadata": {
        "id": "fL6x0wF55R1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Labels\n",
        "\n",
        "# Split into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)  # Increase max_iter to ensure convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc_okLHw8NYY",
        "outputId": "48a19e82-862c-4523-f37e-4fb5a6af55bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')**\n",
        "**and print the model accuracy.**"
      ],
      "metadata": {
        "id": "h7OYJyf85aXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# For binary classification (L1 performs better in binary), pick two classes\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "# Standardize the features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train a Logistic Regression model with L1 regularization\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"L1-Regularized Logistic Regression Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n4jw8Wf8ZxG",
        "outputId": "d62a33e8-fbfb-42f6-a3bc-ba8957dcaba2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1-Regularized Logistic Regression Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using**\n",
        "**LogisticRegression(penalty='l2'). Print model accuracy and coefficients.**"
      ],
      "metadata": {
        "id": "lsBnCiIx5ixx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Standardize the features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train logistic regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, multi_class='multinomial')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print accuracy and coefficients\n",
        "print(f\"L2-Regularized Logistic Regression Accuracy: {accuracy:.2f}\")\n",
        "print(\"Model Coefficients (one row per class):\")\n",
        "print(model.coef_)\n",
        "print(\"Intercepts:\")\n",
        "print(model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFJLT_4w8t0V",
        "outputId": "9e38583c-2de4-4028-a4a8-427a237657b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2-Regularized Logistic Regression Accuracy: 1.00\n",
            "Model Coefficients (one row per class):\n",
            "[[-1.02102589  1.1315509  -1.81471682 -1.68763103]\n",
            " [ 0.53439559 -0.28357112 -0.34273213 -0.73103351]\n",
            " [ 0.4866303  -0.84797979  2.15744895  2.41866455]]\n",
            "Intercepts:\n",
            "[-0.24853241  1.97284408 -1.72431167]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').**"
      ],
      "metadata": {
        "id": "RIG6Ro1W5p9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "# Suppress convergence warnings for demonstration\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# For simplicity, reduce to a binary classification problem\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "# Standardize features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression with Elastic Net regularization\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    l1_ratio=0.5,          # Balance between L1 and L2 (0.5 = equal mix)\n",
        "    max_iter=1000\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output\n",
        "print(f\"Elastic Net Logistic Regression Accuracy: {accuracy:.2f}\")\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n",
        "print(\"Intercept:\")\n",
        "print(model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t6aswAB82hG",
        "outputId": "9b93766f-c85c-4c24-9d65-89f73ac73673"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Logistic Regression Accuracy: 1.00\n",
            "Model Coefficients:\n",
            "[[ 0.5858585  -0.99447532  1.64489004  1.64361989]]\n",
            "Intercept:\n",
            "[0.25376283]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. Write a Python program to train a Logistic Regression model for multiclass classification using**\n",
        "**multi_class='ovr'.**"
      ],
      "metadata": {
        "id": "u3We_ZPu5v1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset (3-class classification)\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression with One-vs-Rest multiclass strategy\n",
        "model = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    solver='lbfgs',        # 'lbfgs' supports OvR and is efficient for multiclass\n",
        "    multi_class='ovr',\n",
        "    max_iter=200\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"One-vs-Rest Logistic Regression Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print coefficients\n",
        "print(\"Model Coefficients (one row per class):\")\n",
        "print(model.coef_)\n",
        "print(\"Intercepts:\")\n",
        "print(model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvhHD_Bv9Dd7",
        "outputId": "e58cea0b-8559-48aa-e1ac-57a16e925c2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-Rest Logistic Regression Accuracy: 0.97\n",
            "Model Coefficients (one row per class):\n",
            "[[-1.01833481  1.17250378 -1.67528697 -1.53588846]\n",
            " [ 0.25903156 -1.25541048  0.54726533 -0.74253705]\n",
            " [ 0.1819854  -0.64013075  2.3344866   2.86191958]]\n",
            "Intercepts:\n",
            "[-2.41957815 -0.87535907 -3.57467368]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic**\n",
        "**Regression. Print the best parameters and accuracy.**"
      ],
      "metadata": {
        "id": "PfEwkwSw51Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Sample dataset (Replace with your own dataset)\n",
        "X = np.random.rand(500, 5)  # 500 samples, 5 features\n",
        "y = np.random.randint(0, 2, 500)  # Binary labels (0 or 1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model and hyperparameter grid\n",
        "model = LogisticRegression(solver='liblinear')  # 'liblinear' supports L1 and L2 regularization\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],   # Regularization strength\n",
        "    'penalty': ['l1', 'l2']    # Type of regularization\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best parameters and accuracy\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Test Set Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tilDwHD9LdZ",
        "outputId": "6ea744b6-e6a5-45af-c39f-fff4e0601945"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.01, 'penalty': 'l1'}\n",
            "Test Set Accuracy: 0.4300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the**\n",
        "**average accuracy.**"
      ],
      "metadata": {
        "id": "HHlYm3y157tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define Logistic Regression model\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, multi_class='ovr')\n",
        "\n",
        "# Set up Stratified K-Fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and compute accuracy for each fold\n",
        "scores = cross_val_score(model, X_scaled, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Output results\n",
        "print(\"Accuracy for each fold:\", scores)\n",
        "print(f\"Average Accuracy: {np.mean(scores):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zbmcCFb-GZk",
        "outputId": "3a9e9859-552c-4510-c1b0-708edcdc1c37"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each fold: [0.93333333 0.96666667 0.86666667 0.96666667 0.86666667]\n",
            "Average Accuracy: 0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its**\n",
        "**accuracy.**"
      ],
      "metadata": {
        "id": "aeujc-ep6BvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from CSV file\n",
        "# Replace 'your_dataset.csv' with your actual CSV file path\n",
        "df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Separate features and target (assumes target column is named 'target')\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output\n",
        "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "Y2oBZeuV-UNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in**\n",
        "**Logistic Regression. Print the best parameters and accuracy.**"
      ],
      "metadata": {
        "id": "hsfdgbW-6GyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Sample dataset (Replace with your own dataset)\n",
        "X = np.random.rand(500, 5)  # 500 samples, 5 features\n",
        "y = np.random.randint(0, 2, 500)  # Binary labels (0 or 1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Define hyperparameter search space\n",
        "param_dist = {\n",
        "    'C': np.logspace(-2, 2, 10),  # Range of regularization strengths\n",
        "    'penalty': ['l1', 'l2'],  # Type of regularization\n",
        "    'solver': ['liblinear', 'saga', 'lbfgs']  # Solvers that support the penalties\n",
        "}\n",
        "\n",
        "# Apply RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(model, param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best parameters and accuracy\n",
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Test Set Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Brf6oAKxFcER",
        "outputId": "b72e02f1-9632-4286-b47d-fbbefcd17de5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': np.float64(100.0)}\n",
            "Test Set Accuracy: 0.5700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.**"
      ],
      "metadata": {
        "id": "xOpp3ktT6NGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Sample dataset (Replace with real dataset)\n",
        "X = np.random.rand(500, 5)  # 500 samples, 5 features\n",
        "y = np.random.randint(0, 3, 500)  # 3 classes (0, 1, 2)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply One-vs-One (OvO) Logistic Regression\n",
        "model = OneVsOneClassifier(LogisticRegression(solver='lbfgs', multi_class='auto'))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print accuracy\n",
        "print(f\"Test Set Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH_wZz5-Gem4",
        "outputId": "13855171-5120-4748-da83-8fb30e113388"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Accuracy: 0.3600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary**\n",
        "**classification.**"
      ],
      "metadata": {
        "id": "bl_UMst36SNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "\n",
        "# Load binary classification dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "class_names = data.target_names\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pTvmJUpvGwPf",
        "outputId": "027b2a52-9674-49b1-bc9f-e74150b22bc1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.97\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,**\n",
        "**Recall, and F1-Score.**"
      ],
      "metadata": {
        "id": "3jioRLyz6ZPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Load binary classification dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-Score:  {f1:.2f}\")\n",
        "\n",
        "# Optionally, print full classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjLK02hKG-ni",
        "outputId": "804fe365-50a5-4c13-b517-2f8b6ee2e0ec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.97\n",
            "Recall:    0.99\n",
            "F1-Score:  0.98\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.98      0.95      0.96        43\n",
            "      benign       0.97      0.99      0.98        71\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to**\n",
        "**improve model performance.**"
      ],
      "metadata": {
        "id": "QLHc-wgI6ho-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2,\n",
        "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train Logistic Regression with class_weight='balanced'\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Class 0', 'Class 1'],\n",
        "            yticklabels=['Class 0', 'Class 1'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "Zd3UTr5lHKNB",
        "outputId": "dd8208ec-69d2-45c1-e5f9-f24cea3363b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.90      0.94       180\n",
            "           1       0.47      0.80      0.59        20\n",
            "\n",
            "    accuracy                           0.89       200\n",
            "   macro avg       0.72      0.85      0.76       200\n",
            "weighted avg       0.93      0.89      0.90       200\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and**\n",
        "**evaluate performance.**"
      ],
      "metadata": {
        "id": "qb0F8mbP6n07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Select relevant features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Drop rows with missing target\n",
        "df = df.dropna(subset=['survived'])\n",
        "\n",
        "# Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical variables to numeric\n",
        "df = pd.get_dummies(df, columns=['sex', 'embarked'], drop_first=True)\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print performance metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbNi2WOQHWVM",
        "outputId": "a7eaf2aa-aa8f-4d53-8d8d-50c1fad6149c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85       110\n",
            "           1       0.79      0.67      0.72        69\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.80      0.78      0.79       179\n",
            "weighted avg       0.80      0.80      0.80       179\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-09d3932ec6a0>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['age'].fillna(df['age'].median(), inplace=True)\n",
            "<ipython-input-19-09d3932ec6a0>:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression**\n",
        "**model. Evaluate its accuracy and compare results with and without scaling.**"
      ],
      "metadata": {
        "id": "CNKvRIGz6uL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------- Model WITHOUT Scaling -----------\n",
        "model_no_scaling = LogisticRegression(max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# ----------- Model WITH Standardization -----------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# ----------- Results -----------\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.2f}\")\n",
        "print(f\"Accuracy with standardization: {accuracy_scaled:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oljaCfOlHlWZ",
        "outputId": "67eef7d2-076b-46c8-c910-9662134bf1ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.96\n",
            "Accuracy with standardization: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.**"
      ],
      "metadata": {
        "id": "GqZBbwFW61EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_scores = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_scores)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "MMcfGNduHyOh",
        "outputId": "8c638d71-84c6-4e8a-c91c-35f6aa3a4b86"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17.  Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate**\n",
        "**accuracy.**"
      ],
      "metadata": {
        "id": "fHRy8noX67Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression with C=0.5\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy with C=0.5: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2ZtzsA8H-DC",
        "outputId": "491b26d7-63a9-4135-ca76-e45c62c2f0ff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18. Write a Python program to train Logistic Regression and identify important features based on model**\n",
        "**coefficients.**"
      ],
      "metadata": {
        "id": "iS3g7nAy7Brf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get feature importance from coefficients\n",
        "coefficients = model.coef_[0]\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients,\n",
        "    'Importance (abs)': np.abs(coefficients)\n",
        "})\n",
        "\n",
        "# Sort features by absolute coefficient value\n",
        "important_features = feature_importance.sort_values(by='Importance (abs)', ascending=False)\n",
        "\n",
        "# Display top features\n",
        "print(\"Top 10 Important Features Based on Logistic Regression Coefficients:\\n\")\n",
        "print(important_features.head(10).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkbn9qSVIL-K",
        "outputId": "c6dd8dea-a282-4824-f0b1-8b794dc0f2c5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Important Features Based on Logistic Regression Coefficients:\n",
            "\n",
            "             Feature  Coefficient  Importance (abs)\n",
            "       worst texture    -1.255088          1.255088\n",
            "        radius error    -1.082965          1.082965\n",
            "worst concave points    -0.953686          0.953686\n",
            "          worst area    -0.947756          0.947756\n",
            "        worst radius    -0.947616          0.947616\n",
            "      worst symmetry    -0.939181          0.939181\n",
            "          area error    -0.929104          0.929104\n",
            "     worst concavity    -0.823151          0.823151\n",
            "     worst perimeter    -0.763220          0.763220\n",
            "    worst smoothness    -0.746625          0.746625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa**\n",
        "**Score.**"
      ],
      "metadata": {
        "id": "IjpuHnXa7MVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate using Cohen's Kappa Score\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Cohen's Kappa Score: {kappa:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sws3Rm23IYcD",
        "outputId": "f8e8343d-f406-44a6-b3ec-9f385f622499"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary**\n",
        "**classification.**"
      ],
      "metadata": {
        "id": "GeYB7DP17Sz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_scores = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Compute precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "average_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(recall, precision, label=f'AP = {average_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "1HrOu3ukIkBK",
        "outputId": "768b6bfa-a840-4b9b-c6fa-a302ccbf6a70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare**\n",
        "**their accuracy.**"
      ],
      "metadata": {
        "id": "_vhXPrNF7cIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Solvers to compare\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "print(\"Accuracy comparison of Logistic Regression solvers:\\n\")\n",
        "for solver in solvers:\n",
        "    try:\n",
        "        model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Solver: {solver:9s} -> Accuracy: {accuracy:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Solver: {solver:9s} -> Failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_0b25r9Iur_",
        "outputId": "7c3ad969-39c1-48e8-9e82-7945c2f43fbb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy comparison of Logistic Regression solvers:\n",
            "\n",
            "Solver: liblinear -> Accuracy: 0.9825\n",
            "Solver: saga      -> Accuracy: 0.9825\n",
            "Solver: lbfgs     -> Accuracy: 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews**\n",
        "**Correlation Coefficient (MCC).**"
      ],
      "metadata": {
        "id": "xUjmS5z-7kK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate using Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q87tyRXhI6CT",
        "outputId": "57cfa7b8-e1a4-4be7-e42f-295143d9b250"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.9623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their**\n",
        "**accuracy to see the impact of feature scaling.**"
      ],
      "metadata": {
        "id": "EAhdktXO7qZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -------- Train on Raw (Unscaled) Data --------\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# -------- Train on Standardized (Scaled) Data --------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# -------- Results --------\n",
        "print(\"Logistic Regression Accuracy Comparison:\")\n",
        "print(f\"- Without Scaling:  {accuracy_raw:.4f}\")\n",
        "print(f\"- With Scaling:     {accuracy_scaled:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiNrPZgpJGgK",
        "outputId": "ee159f03-f701-4da8-e770-c3f5cc2fbbd0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy Comparison:\n",
            "- Without Scaling:  0.9649\n",
            "- With Scaling:     0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using**\n",
        "**cross-validation.**"
      ],
      "metadata": {
        "id": "zBZc9Py77xLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define model and hyperparameter grid\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "param_grid = {\n",
        "    'C': np.logspace(-4, 4, 10)  # Try values of C from 1e-4 to 1e4\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get best results\n",
        "best_C = grid_search.best_params_['C']\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"Best C (Regularization Strength): {best_C}\")\n",
        "print(f\"Cross-Validated Accuracy: {best_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxp9C8hYJSJK",
        "outputId": "18cda26d-dcf5-4657-d3d6-3888c75f7bd3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C (Regularization Strength): 0.3593813663804626\n",
            "Cross-Validated Accuracy: 0.9780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to**\n",
        "**make predictions.**"
      ],
      "metadata": {
        "id": "0NWcyokY73PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Save the model and scaler\n",
        "joblib.dump(model, \"logistic_model.joblib\")\n",
        "joblib.dump(scaler, \"scaler.joblib\")\n",
        "\n",
        "print(\"Model and scaler saved successfully.\")\n",
        "\n",
        "# Load the model and scaler\n",
        "loaded_model = joblib.load(\"logistic_model.joblib\")\n",
        "loaded_scaler = joblib.load(\"scaler.joblib\")\n",
        "\n",
        "# Scale the test data again using the loaded scaler\n",
        "X_test_scaled_loaded = loaded_scaler.transform(X_test)\n",
        "\n",
        "# Make predictions with the loaded model\n",
        "y_pred = loaded_model.predict(X_test_scaled_loaded)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of loaded model: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INbaaAHRJdZ7",
        "outputId": "2848de40-cf8b-454d-9c5b-544857a0209b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and scaler saved successfully.\n",
            "Accuracy of loaded model: 0.9825\n"
          ]
        }
      ]
    }
  ]
}